{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting ChromaDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-Memory / Ephemeral Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "# chroma_client = chromadb.Client()\n",
    "# collection = chroma_client.get_collection() # get the list of collections in this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistent Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "\n",
    "# chroma_client = chromadb.PersistentClient(path=\"Storage/persistent_storage\")\n",
    "# collection = chroma_client.get_collection() # get the list of collections in this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client Server Mode\n",
    "\n",
    "Client Vs Persistent\n",
    "- Client is just seting up a connection to Persistent server\n",
    "- So if a remote project use persistent, but if planning to scale the project use Client \n",
    "- personally i will use client as i will be learning to work in a company\n",
    "- only syntax changes i would recommend seeing docs, i will mention the persistent syntax as much as i can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it runs like MySQL\n",
    "# run this command : \n",
    "\"\"\"\n",
    "chroma run \\\n",
    "  --path ./path/to/ \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000 \\\n",
    "  --log-level DEBUG \\\n",
    "  --settings ./settings.json \\\n",
    "  --impl rest\n",
    "\n",
    "my command\n",
    "  chroma run \\\n",
    "  --path ./Storage/server \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000 \\\n",
    "  --log-level DEBUG \\\n",
    "  --settings ./settings.json \\\n",
    "  --impl rest\n",
    "\"\"\"\n",
    "\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "collection = chroma_client.get_collection() # get the list of collections in this server\n",
    "\n",
    "\n",
    "# adding Asyncronous Behaviour\n",
    "\n",
    "# import asyncio\n",
    "# import chromadb\n",
    "\n",
    "# async def main():\n",
    "#     client = await chromadb.AsyncHttpClient()\n",
    "\n",
    "#     collection = await client.create_collection(name=\"my_collection\")\n",
    "#     await collection.add(\n",
    "#         documents=[\"hello world\"],\n",
    "#         ids=[\"id1\"]\n",
    "#     )\n",
    "\n",
    "# asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Embedding models\n",
    "> **Note:** \n",
    "> - Only to be used in In-Memory or Persistent not in Server\n",
    "> - For Server We need to pass embedding model too when adding.\n",
    "> -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyanshusinghania/Documents/Github/DataBases/DBvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# I am using hugginf face and not following documents here\n",
    "# I will tell further why\n",
    "\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_fn = SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "# collection = chroma_client.create_collection(name=\"my_collection\")\n",
    "collection = chroma_client.create_collection(name=\"my_collection\", embedding_function=embedding_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Persistent Storage and In Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\"\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\"],\n",
    "    metadatas=[{\"source\": \"I love Colors\"}, {\"source\": \"I Love Hawaii\"}]\n",
    ")\n",
    "# --------------------------------------------------\n",
    "#                        |\n",
    "#                        V\n",
    "# This will through error on macos intel chips (atleast in my case)\n",
    "# If i used default embedding function we get a onnx model and\n",
    "# cause onnx core ml is not supported well on this system\n",
    "# I have to change my embedding model from hugging face \n",
    "# and hence deviated from Docs earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Server Client Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedding = model.encode([\"Chroma is an embedding database\"]).tolist()\n",
    "\n",
    "collection.add(\n",
    "    ids=[\"id1\"],\n",
    "    embeddings=embedding, # Embeddings of Documents\n",
    "    documents=[\"Chroma is an embedding database\"],\n",
    "    metadatas=[{\"source\": \"ChromaDB Docs\"}]\n",
    ")\n",
    "\n",
    "# So whenever i am using langchain, i will use embed model on docs\n",
    "# then add in chromaDB server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert in Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert a document\n",
    "collection.upsert(\n",
    "    ids=[\"doc1\"],  # Document ID\n",
    "    documents=[\"Updated content\"],  # New or updated document content\n",
    "    metadatas=[{\"category\": \"science\"}],  # Updated metadata\n",
    "    embeddings=[[0.1, 0.2, 0.3, ...]]  # Updated embedding vector\n",
    ")\n",
    "\n",
    "# It Replaces the whole doc not append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete documents by their IDs\n",
    "collection.delete(ids=[\"doc1\", \"doc2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delet Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a collection by name\n",
    "chroma_client.delete_collection(name=\"my_collection\")\n",
    "chroma_client.reset() # Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qurying Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id1', 'id2']], 'embeddings': None, 'documents': [['This is a document about pineapple', 'This is a document about oranges']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None, None]], 'distances': [[1.0404011011123657, 1.2430799007415771]]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    # Chroma will embed this for you in persistent and in memory storage\n",
    "    query_texts=[\"This is a query document about hawaii\"], \n",
    "\n",
    "    # using Meta tags\n",
    "    where={\"source\": \"wiki\"}, \n",
    "\n",
    "    # Returns document that have phrase \"Quamtum Mechanics\"\n",
    "    where_document={\"$contains\": \"quantum mechanics\"}, \n",
    "\n",
    "    # how many results to return\n",
    "    n_results=2,\n",
    "\n",
    "    # Includes the spcific field, can be used in cosine similarity search\n",
    "    include=[\"distances\"]\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "# For server you must pass Query embeddings\n",
    "# Here you can also pass an image eembeddings for multi-modal Query\n",
    "# and it retrieve most relevant Documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DBvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
